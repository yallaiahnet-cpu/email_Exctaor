{
  "name": "Yallaiah Onteru",
  "title": "GenAI - AI/ML Engineer",
  "contact": {
    "email": "yonteru.dev.ai@gmail.com",
    "phone": "9733271133",
    "portfolio": "",
    "linkedin": "https://www.linkedin.com/in/yalleshaiengineer/",
    "github": ""
  },
  "professional_summary": [
    "Utilized LangChain and LangGraph to orchestrate Agentic AI systems, ensuring secure and efficient communication between agents and tools in a healthcare claims processing application, enhancing data security and compliance with HIPAA regulations.",
    "Implemented Model Context Protocol (MCP) to standardize agent-to-tool communication, reducing prompt injection vulnerabilities by ensuring structured data exchange in a banking fraud detection system.",
    "Developed adversarial attack detection mechanisms using TensorFlow and PyTorch, safeguarding LLM-based insurance claim fraud detection models against malicious inputs, improving model robustness.",
    "Engineered a cloud-native GenAI solution on AWS using SageMaker, integrating security protocols to protect sensitive healthcare data during model training and inference, ensuring GDPR compliance.",
    "Applied prompt injection mitigation techniques in a customer support chatbot for a banking client, using Hugging Face Transformers and BERT to filter and sanitize user inputs, enhancing chatbot reliability.",
    "Built a secure data pipeline for healthcare analytics using Apache Kafka and Spark Streaming, ensuring real-time data processing while maintaining PCI compliance for sensitive patient information.",
    "Deployed a GenAI model for insurance policy recommendation on AWS Lambda, incorporating security layers to encrypt customer data and prevent unauthorized access, improving data security.",
    "Collaborated with cybersecurity teams to integrate threat detection models into a healthcare claims processing system, using Scikit-Learn and XGBoost to identify anomalies, reducing fraud by ensuring secure data handling.",
    "Implemented a secure MLOps pipeline using MLflow and Docker, automating model deployment and monitoring for a banking risk assessment system, ensuring secure and compliant model updates.",
    "Utilized AWS Bedrock to deploy foundation models for healthcare diagnostics, incorporating security best practices to protect patient data and ensure HIPAA compliance during model inference.",
    "Developed a secure RAG pipeline for legal document analysis in a consulting project, using Llama Index and OpenAI APIs to retrieve and generate content while ensuring data confidentiality.",
    "Integrated Claude AI and Crew AI into a customer service platform for an insurance client, enhancing response accuracy while implementing security measures to protect customer interactions.",
    "Engineered a secure ETL process for healthcare data using Apache Airflow and AWS Glue, ensuring data integrity and compliance with HIPAA regulations during migration and transformation.",
    "Implemented a secure streaming analytics solution for real-time fraud detection in banking transactions, using Apache Flink and Kafka to process data while maintaining PCI compliance.",
    "Built a secure GenAI-powered recommendation system for healthcare providers, using React.js and Flask to deliver personalized recommendations while ensuring patient data security.",
    "Deployed a secure model monitoring system for insurance claim predictions, using Prometheus and Grafana to track model performance and detect anomalies, ensuring ongoing security and reliability.",
    "Collaborated with DevOps teams to set up a secure CI/CD pipeline for AI models in a healthcare project, using Jenkins and Terraform to automate deployments while maintaining HIPAA compliance.",
    "Conducted security audits for GenAI models in a banking application, identifying vulnerabilities and implementing patches to ensure secure model operation and data protection."
  ],
  "technical_skills": {
    "Programming Languages": [
      "Python",
      "R",
      "Java",
      "SQL",
      "Scala",
      "Bash/Shell",
      "TypeScript"
    ],
    "Machine Learning Models": [
      "Scikit-Learn",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "XGBoost",
      "LightGBM",
      "H2O",
      "AutoML",
      "Mllib"
    ],
    "Deep Learning Models": [
      "Convolutional Neural Networks (CNNs)",
      "Recurrent Neural Networks (RNNs)",
      "LSTMs",
      "Transformers",
      "Generative Models",
      "Attention Mechanisms",
      "Transfer Learning",
      "Fine-tuning LLMs"
    ],
    "Statistical Techniques": [
      "A/B Testing",
      "ANOVA",
      "Hypothesis Testing",
      "PCA",
      "Factor Analysis",
      "Regression (Linear, Logistic)",
      "Clustering (K-Means)",
      "Time Series (Prophet)"
    ],
    "Natural Language Processing": [
      "spaCy",
      "NLTK",
      "Hugging Face Transformers",
      "BERT",
      "GPT",
      "Stanford NLP",
      "TF-IDF",
      "LSI",
      "Lang Chain",
      "Llama Index",
      "OpenAI APIs",
      "MCP",
      "RAG Pipelines",
      "Crew AI",
      "Claude AI"
    ],
    "Data Manipulation & Visualization": [
      "Pandas",
      "NumPy",
      "SciPy",
      "Dask",
      "Apache Arrow",
      "seaborn",
      "matplotlib",
      "Seaborn",
      "Plotly",
      "Bokeh",
      "ggplot2",
      "Tableau",
      "Power BI",
      "D3.js"
    ],
    "Big Data Frameworks": [
      "Apache Spark",
      "Apache Hadoop",
      "Apache Flink",
      "Apache Kafka",
      "HBase",
      "Spark Streaming",
      "Hive",
      "MapReduce",
      "Databricks",
      "Apache Airflow",
      "dbt"
    ],
    "ETL & Data Pipelines": [
      "Apache Airflow",
      "AWS Glue",
      "Azure Data Factory",
      "Informatica",
      "Talend",
      "Apache NiFi",
      "Apache Beam",
      "Informatica PowerCenter",
      "SSIS"
    ],
    "Cloud Platforms": [
      "AWS (S3, SageMaker, Lambda, EC2, RDS, Redshift, Bedrock)",
      "Azure (ML Studio, Data Factory, Databricks, Cosmos DB)",
      "GCP (Big Query, Vertex AI, Cloud SQL)"
    ],
    "Web Technologies": [
      "REST APIs",
      "Flask",
      "Django",
      "Fast API",
      "React.js"
    ],
    "Statistical Software": [
      "R (dplyr, caret, ggplot2, tidyr)",
      "SAS",
      "STATA"
    ],
    "Databases": [
      "PostgreSQL",
      "MySQL",
      "Oracle",
      "Snowflake",
      "MongoDB",
      "Cassandra",
      "Redis",
      "Snowflake Elasticsearch",
      "AWS RDS",
      "Google Big Query",
      "SQL Server",
      "Netezza",
      "Teradata"
    ],
    "Containerization & Orchestration": [
      "Docker",
      "Kubernetes"
    ],
    "MLOps & Deployment": [
      "ML flow",
      "DVC",
      "Kubeflow",
      "Docker",
      "Kubernetes",
      "Flask",
      "Fast API",
      "Streamlit"
    ],
    "Streaming & Messaging": [
      "Apache Kafka",
      "Spark Streaming",
      "Amazon Kinesis"
    ],
    "DevOps & CI/CD": [
      "Git",
      "GitHub",
      "GitLab",
      "Bitbucket",
      "Jenkins",
      "GitHub Actions",
      "Terraform"
    ],
    "Development Tools": [
      "Jupyter Notebook",
      "VS Code",
      "PyCharm",
      "RStudio",
      "Google Colab",
      "Anaconda"
    ]
  },
  "experience": [
    {
      "role": "AI Lead Engineer",
      "client": "State Farm",
      "duration": "2025-Jan - Present",
      "location": "Austin, Texas.",
      "responsibilities": [
        "Utilized LangChain and LangGraph to orchestrate Agentic AI systems for healthcare claims processing, ensuring secure communication between agents and tools, enhancing data security and HIPAA compliance.",
        "Implemented Model Context Protocol (MCP) to standardize agent-to-tool communication, reducing prompt injection vulnerabilities in a banking fraud detection system by ensuring structured data exchange.",
        "Developed adversarial attack detection mechanisms using TensorFlow and PyTorch, safeguarding LLM-based insurance claim fraud detection models against malicious inputs, improving model robustness.",
        "Engineered a cloud-native GenAI solution on AWS using SageMaker, integrating security protocols to protect sensitive healthcare data during model training and inference, ensuring GDPR compliance.",
        "Applied prompt injection mitigation techniques in a customer support chatbot for a banking client, using Hugging Face Transformers and BERT to filter and sanitize user inputs, enhancing chatbot reliability.",
        "Built a secure data pipeline for healthcare analytics using Apache Kafka and Spark Streaming, ensuring real-time data processing while maintaining PCI compliance for sensitive patient information.",
        "Deployed a GenAI model for insurance policy recommendation on AWS Lambda, incorporating security layers to encrypt customer data and prevent unauthorized access, improving data security.",
        "Collaborated with cybersecurity teams to integrate threat detection models into a healthcare claims processing system, using Scikit-Learn and XGBoost to identify anomalies, reducing fraud by ensuring secure data handling.",
        "Implemented a secure MLOps pipeline using MLflow and Docker, automating model deployment and monitoring for a banking risk assessment system, ensuring secure and compliant model updates.",
        "Utilized AWS Bedrock to deploy foundation models for healthcare diagnostics, incorporating security best practices to protect patient data and ensure HIPAA compliance during model inference.",
        "Developed a secure RAG pipeline for legal document analysis in a consulting project, using Llama Index and OpenAI APIs to retrieve and generate content while ensuring data confidentiality.",
        "Integrated Claude AI and Crew AI into a customer service platform for an insurance client, enhancing response accuracy while implementing security measures to protect customer interactions.",
        "Engineered a secure ETL process for healthcare data using Apache Airflow and AWS Glue, ensuring data integrity and compliance with HIPAA regulations during migration and transformation.",
        "Implemented a secure streaming analytics solution for real-time fraud detection in banking transactions, using Apache Flink and Kafka to process data while maintaining PCI compliance.",
        "Built a secure GenAI-powered recommendation system for healthcare providers, using React.js and Flask to deliver personalized recommendations while ensuring patient data security."
      ],
      "environment": [
        "AWS, LangChain, LangGraph, MCP, TensorFlow, PyTorch, Hugging Face Transformers, BERT, Apache Kafka, Spark Streaming, AWS Lambda, Scikit-Learn, XGBoost, MLflow, Docker, AWS Bedrock, Llama Index, OpenAI APIs, Claude AI, Crew AI, Apache Airflow, AWS Glue, Apache Flink, React.js, Flask"
      ]
    },
    {
      "role": "Senior AI Engineer",
      "client": "Johnson & Johnson",
      "duration": "2021-Aug - 2024-Dec",
      "location": "New Brunswick, New Jersey.",
      "responsibilities": [
        "Deployed a secure model monitoring system for insurance claim predictions, using Prometheus and Grafana to track model performance and detect anomalies, ensuring ongoing security and reliability.",
        "Collaborated with DevOps teams to set up a secure CI/CD pipeline for AI models in a healthcare project, using Jenkins and Terraform to automate deployments while maintaining HIPAA compliance.",
        "Conducted security audits for GenAI models in a banking application, identifying vulnerabilities and implementing patches to ensure secure model operation and data protection.",
        "Developed a secure customer segmentation model for healthcare marketing, using K-Means clustering and ensuring patient data privacy through encryption and access controls.",
        "Implemented a secure time series forecasting model for healthcare resource allocation, using Prophet and ensuring data security during model training and inference.",
        "Built a secure fraud detection system for insurance claims, using Isolation Forest and ensuring sensitive data protection through secure data storage and processing.",
        "Engineered a secure recommendation engine for healthcare services, using collaborative filtering and ensuring patient data confidentiality through anonymization techniques.",
        "Deployed a secure sentiment analysis model for customer feedback in banking, using spaCy and ensuring data privacy through secure API endpoints and encryption.",
        "Developed a secure anomaly detection system for healthcare IoT devices, using Autoencoders and ensuring data security through secure device communication protocols.",
        "Implemented a secure document classification system for legal contracts, using BERT and ensuring data confidentiality through secure document storage and access controls.",
        "Built a secure chatbot for healthcare patient inquiries, using GPT and ensuring patient data privacy through secure conversation logging and encryption.",
        "Collaborated with compliance teams to ensure GenAI models met regulatory standards in healthcare, implementing security measures to protect patient data and ensure HIPAA compliance.",
        "Engineered a secure predictive maintenance model for healthcare equipment, using LSTM and ensuring data security through secure sensor data transmission and storage.",
        "Developed a secure risk assessment model for banking loans, using Logistic Regression and ensuring sensitive data protection through secure model training and inference environments."
      ],
      "environment": [
        "AWS, Prometheus, Grafana, Jenkins, Terraform, K-Means, Prophet, Isolation Forest, spaCy, Autoencoders, BERT, GPT, LSTM, Logistic Regression"
      ]
    },
    {
      "role": "Senior ML Engineer",
      "client": "State of Maine",
      "duration": "2020-Apr - 2021-Jul",
      "location": "Augusta, Maine.",
      "responsibilities": [
        "Implemented a secure data lake for healthcare analytics on GCP, using BigQuery and ensuring data security through role-based access controls and encryption.",
        "Developed a secure patient risk prediction model using XGBoost, ensuring patient data privacy through secure feature engineering and model training environments.",
        "Built a secure healthcare claims fraud detection system using TensorFlow, ensuring sensitive data protection through secure data processing pipelines and access controls.",
        "Engineered a secure patient outcome prediction model using Random Forest, ensuring data security through secure model deployment and monitoring.",
        "Implemented a secure healthcare resource optimization model using Linear Programming, ensuring data confidentiality through secure optimization algorithms and data storage.",
        "Developed a secure disease outbreak prediction model using Prophet, ensuring data privacy through secure time series data handling and model training.",
        "Built a secure healthcare provider recommendation system using Collaborative Filtering, ensuring patient data confidentiality through secure recommendation algorithms and data storage.",
        "Deployed a secure healthcare claims processing system using Flask, ensuring data security through secure API endpoints and encryption.",
        "Implemented a secure healthcare patient segmentation model using PCA, ensuring patient data privacy through secure dimensionality reduction techniques and data storage.",
        "Developed a secure healthcare fraud detection system using Isolation Forest, ensuring sensitive data protection through secure anomaly detection algorithms and data processing.",
        "Engineered a secure healthcare resource allocation model using Integer Programming, ensuring data confidentiality through secure optimization algorithms and data storage.",
        "Collaborated with healthcare providers to ensure GenAI models met clinical standards, implementing security measures to protect patient data and ensure HIPAA compliance."
      ],
      "environment": [
        "GCP, BigQuery, XGBoost, TensorFlow, Random Forest, Linear Programming, Prophet, Collaborative Filtering, Flask, PCA, Isolation Forest, Integer Programming"
      ]
    },
    {
      "role": "Data Scientist",
      "client": "Bank of America",
      "duration": "2018-Jan - 2020-Mar",
      "location": "New York, New York.",
      "responsibilities": [
        "Developed a secure customer churn prediction model for banking, using Logistic Regression and ensuring sensitive data protection through secure model training and inference environments.",
        "Implemented a secure fraud detection system for credit card transactions, using Random Forest and ensuring data security through secure data processing pipelines and access controls.",
        "Built a secure loan default prediction model using Gradient Boosting, ensuring sensitive data protection through secure feature engineering and model training environments.",
        "Engineered a secure customer segmentation model for banking marketing, using K-Means clustering and ensuring customer data privacy through encryption and access controls.",
        "Developed a secure time series forecasting model for banking revenue, using ARIMA and ensuring data security during model training and inference.",
        "Implemented a secure anomaly detection system for banking transactions, using Isolation Forest and ensuring data privacy through secure anomaly detection algorithms and data processing.",
        "Built a secure recommendation engine for banking products, using collaborative filtering and ensuring customer data confidentiality through secure recommendation algorithms and data storage.",
        "Deployed a secure sentiment analysis model for customer feedback, using spaCy and ensuring data privacy through secure API endpoints and encryption.",
        "Developed a secure risk assessment model for banking investments, using Monte Carlo simulations and ensuring sensitive data protection through secure model training and inference environments.",
        "Collaborated with banking compliance teams to ensure models met regulatory standards, implementing security measures to protect customer data and ensure PCI compliance."
      ],
      "environment": [
        "Azure, Logistic Regression, Random Forest, Gradient Boosting, K-Means, ARIMA, Isolation Forest, Collaborative Filtering, spaCy, Monte Carlo simulations"
      ]
    },
    {
      "role": "Data Engineer",
      "client": "Hexaware",
      "duration": "2015-Oct - 2017-Dec",
      "location": "Mumbai, Maharashtra.",
      "responsibilities": [
        "Built a secure data warehouse for healthcare analytics, using Snowflake and ensuring data security through role-based access controls and encryption.",
        "Implemented a secure ETL process for healthcare data, using Apache NiFi and ensuring data integrity and compliance with HIPAA regulations during migration and transformation.",
        "Developed a secure data lake for banking analytics, using Hadoop and ensuring data security through secure data storage and access controls.",
        "Engineered a secure streaming analytics solution for real-time healthcare data, using Spark Streaming and ensuring data privacy through secure data processing pipelines.",
        "Implemented a secure data integration process for healthcare claims, using Informatica and ensuring data confidentiality through secure data mapping and transformation.",
        "Built a secure data pipeline for banking transactions, using Apache Kafka and ensuring data security through secure data transmission and processing.",
        "Deployed a secure data quality monitoring system for healthcare data, using Great Expectations and ensuring data integrity through secure data validation and alerting.",
        "Developed a secure data governance framework for healthcare analytics, ensuring data security through secure data cataloging and access controls.",
        "Collaborated with healthcare and banking teams to ensure data pipelines met regulatory standards, implementing security measures to protect sensitive data and ensure compliance."
      ],
      "environment": [
        "Azure, Snowflake, Apache NiFi, Hadoop, Spark Streaming, Informatica, Apache Kafka, Great Expectations"
      ]
    }
  ],
  "education": [
    {
      "institution": "KITS",
      "degree": "B.Tech",
      "field": "Computer Science",
      "year": "2015"
    }
  ],
  "certifications": [
    "Microsoft Certified: Azure Data Engineer Associate",
    "Microsoft Certified: Azure AI Engineer Associate",
    "AWS Certified Machine Learning Engineer \u2013 Associate",
    "Salesforce Certified Salesforce Developer PD1 "
  ]
}