{
  "name": "Yallaiah Onteru",
  "title": "Data Engineer",
  "contact": {
    "email": "yonteru.dev.ai@gmail.com",
    "phone": "9733271133",
    "portfolio": "",
    "linkedin": "https://www.linkedin.com/in/yalleshaiengineer/",
    "github": ""
  },
  "professional_summary": [
    "Built scalable, intelligent data infrastructure for analytics and machine learning across the enterprise. Collaborated with data scientists, BI developers, and platform engineers to design and operate production-grade pipelines in cloud environments. Utilized Python, SQL, C#/.NET, Java, and Azure to deliver high-quality data deliverables.",
    "Engineered robust data pipelines and ML data pipelines using Databricks, dbt, and MLflow. Designed and implemented API designs and microservices using Python and Azure.",
    "Deployed cloud platforms (Azure) and Databricks to support data engineering and machine learning workloads. Utilized Orchestration tools to manage and monitor data pipelines and ML data pipelines.",
    "Developed feature engineering and ML-oriented tools to support data science and machine learning teams.",
    "Collaborated with cross-functional teams to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
    "Utilized Apache Kafka, Amazon Kinesis, and CI/CD for data pipelines to support real-time data ingestion and MLOps best practices.",
    "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
    "Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
    "Utilized Agile project management methodologies and containerization (Docker) to support data engineering and machine learning workloads.",
    "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
    "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
    "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
    "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
    "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
    "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
    "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
    "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
    "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads."
  ],
  "technical_skills": {
    "Data Engineering": [
      "Python",
      "SQL",
      "C#/.NET",
      "Java",
      "Advanced SQL and distributed data systems",
      "Cloud platforms (Azure)",
      "Databricks",
      "Orchestration tools",
      "API design and microservices",
      "ML data pipelines",
      "Feature engineering",
      "ML-oriented tools (MLflow, TensorFlow Extended (TFX))",
      "dbt",
      "Spark",
      "Delta Lake",
      "WMS or operational logistics data"
    ],
    "Machine Learning": [
      "Apache Kafka",
      "Amazon Kinesis",
      "CI/CD for data pipelines",
      "Data modeling",
      "Data versioning",
      "Model retraining and evaluation",
      "Feature stores",
      "Model input validation",
      "Monitoring pipelines",
      "Metadata management",
      "Data lineage",
      "Auditable transformations"
    ],
    "Cloud Platforms": [
      "Azure Data Factory",
      "Databricks",
      "Azure",
      "Airflow",
      "Kinesis",
      "Kafka",
      "MLflow",
      "TensorFlow Extended (TFX)",
      "dbt",
      "Spark",
      "Delta Lake"
    ],
    "Agile Methodologies": [
      "Version control systems (e.g., Git)",
      "Agile project management tools (e.g., Jira)",
      "Data quality and governance tools (e.g., Trifacta)",
      "BI and analytics tools (e.g., Tableau)"
    ],
    "Containerization": [
      "Docker"
    ]
  },
  "experience": [
    {
      "role": "Senior Data Engineer",
      "client": "Logistics and Warehouse Management Systems",
      "duration": "2025-Jan - Present",
      "location": "Austin, Texas.",
      "responsibilities": [
        "Built scalable, intelligent data infrastructure for analytics and machine learning across the enterprise. Collaborated with data scientists, BI developers, and platform engineers to design and operate production-grade pipelines in cloud environments.",
        "Engineered robust data pipelines and ML data pipelines using Databricks, dbt, and MLflow. Designed and implemented API designs and microservices using Python and Azure.",
        "Deployed cloud platforms (Azure) and Databricks to support data engineering and machine learning workloads. Utilized Orchestration tools to manage and monitor data pipelines and ML data pipelines.",
        "Developed feature engineering and ML-oriented tools to support data science and machine learning teams.",
        "Collaborated with cross-functional teams to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Utilized Apache Kafka, Amazon Kinesis, and CI/CD for data pipelines to support real-time data ingestion and MLOps best practices.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Utilized Agile project management methodologies and containerization (Docker) to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads."
      ],
      "environment": [
        "Azure Data Factory",
        "Databricks",
        "Azure",
        "Airflow",
        "Kinesis",
        "Kafka",
        "MLflow",
        "TensorFlow Extended (TFX)",
        "dbt",
        "Spark",
        "Delta Lake"
      ]
    },
    {
      "role": "Senior Data Engineer",
      "client": "Logistics and Warehouse Management Systems",
      "duration": "2020-Apr - 2024-Dec",
      "location": "Austin, Texas.",
      "responsibilities": [
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads."
      ],
      "environment": [
        "Azure Data Factory",
        "Databricks",
        "Azure",
        "Airflow",
        "Kinesis",
        "Kafka",
        "MLflow",
        "TensorFlow Extended (TFX)",
        "dbt",
        "Spark",
        "Delta Lake"
      ]
    },
    {
      "role": "Data Engineer",
      "client": "Logistics and Warehouse Management Systems",
      "duration": "2018-Jan - 2020-Mar",
      "location": "Austin, Texas.",
      "responsibilities": [
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads.",
        "Collaborated with data scientists to design and operate production-grade pipelines in cloud environments. Utilized data modeling and data versioning to ensure data quality and governance.",
        "Worked closely with data scientists to translate modeling goals into data deliverables. Utilized data governance and quality tools to ensure data quality and governance.",
        "Utilized data modeling and data versioning to ensure data quality and governance. Developed and maintained metadata management and data lineage to support data engineering and machine learning workloads."
      ],
      "environment": [
        "Azure Data Factory",
        "Databricks",
        "Azure",
        "Airflow",
        "Kinesis",
        "Kafka",
        "MLflow",
        "TensorFlow Extended (TFX)",
        "dbt",
        "Spark",
        "Delta Lake"
      ]
    }
  ],
  "education": [
    {
      "institution": "KITS",
      "degree": "B.Tech",
      "field": "Computer Science",
      "year": "2015"
    }
  ],
  "certifications": [
    "Microsoft Certified: Azure Data Engineer Associate",
    "Microsoft Certified: Azure AI Engineer Associate",
    "AWS Certified Machine Learning Engineer \u2013 Associate",
    "Salesforce Certified Salesforce Developer PD1 "
  ]
}